{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa064f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for image processing, deep learning, and visualization\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046a731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU device and check PyTorch/CUDA versions\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8c55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure hyperparameters and data paths for model training\n",
    "IMAGE_DIR  = r\"C:\\Daily drive\\College\\sem 6\\Main Project DL\\data\\xbd\\train\\images\"\n",
    "TARGET_DIR = r\"C:\\Daily drive\\College\\sem 6\\Main Project DL\\data\\xbd\\train\\targets\"\n",
    "\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 6              # reduced (safe & sufficient)\n",
    "NUM_CLASSES = 5\n",
    "MAX_IMAGES = 1200       # üî• reduced dataset (KEY FIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d71ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image files:\n",
      "['guatemala-volcano_00000000_post_disaster.png', 'guatemala-volcano_00000000_pre_disaster.png', 'guatemala-volcano_00000001_post_disaster.png', 'guatemala-volcano_00000001_pre_disaster.png', 'guatemala-volcano_00000002_post_disaster.png']\n",
      "\n",
      "Sample target files:\n",
      "['guatemala-volcano_00000000_post_disaster_target.png', 'guatemala-volcano_00000000_pre_disaster_target.png', 'guatemala-volcano_00000001_post_disaster_target.png', 'guatemala-volcano_00000001_pre_disaster_target.png', 'guatemala-volcano_00000002_post_disaster_target.png']\n"
     ]
    }
   ],
   "source": [
    "# Verify that data files exist and explore sample images and target masks\n",
    "print(\"Sample image files:\")\n",
    "print(os.listdir(IMAGE_DIR)[:5])\n",
    "\n",
    "print(\"\\nSample target files:\")\n",
    "print(os.listdir(TARGET_DIR)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0788938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Dataset class to load and preprocess building damage images and target masks\n",
    "class XBDDataset(Dataset):\n",
    "    def __init__(self, image_dir, target_dir, max_images):\n",
    "        self.image_dir = image_dir\n",
    "        self.target_dir = target_dir\n",
    "\n",
    "        all_images = sorted(os.listdir(image_dir))\n",
    "        self.pairs = []\n",
    "\n",
    "        for img_name in all_images:\n",
    "            # Only use post-disaster images (recommended)\n",
    "            if \"post_disaster\" not in img_name:\n",
    "                continue\n",
    "\n",
    "            mask_name = img_name.replace(\".png\", \"_target.png\")\n",
    "            mask_path = os.path.join(target_dir, mask_name)\n",
    "\n",
    "            if os.path.exists(mask_path):\n",
    "                self.pairs.append((img_name, mask_name))\n",
    "\n",
    "            if len(self.pairs) >= max_images:\n",
    "                break\n",
    "\n",
    "        if len(self.pairs) == 0:\n",
    "            raise RuntimeError(\"‚ùå No matching image-mask pairs found.\")\n",
    "\n",
    "        print(f\"‚úî Matched image-mask pairs: {len(self.pairs)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, mask_name = self.pairs[idx]\n",
    "\n",
    "        img = cv2.imread(os.path.join(self.image_dir, img_name))\n",
    "        mask = cv2.imread(\n",
    "            os.path.join(self.target_dir, mask_name),\n",
    "            cv2.IMREAD_GRAYSCALE\n",
    "        )\n",
    "\n",
    "        # Safety fallback\n",
    "        if img is None or mask is None:\n",
    "            new_idx = np.random.randint(0, len(self.pairs))\n",
    "            return self.__getitem__(new_idx)\n",
    "\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = img / 255.0\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "        mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f06758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Matched image-mask pairs: 1200\n",
      "Training samples: 1200\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset and dataloader for batch processing\n",
    "train_dataset = XBDDataset(\n",
    "    IMAGE_DIR,\n",
    "    TARGET_DIR,\n",
    "    MAX_IMAGES\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,   # Windows-safe\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ee03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UNet architecture for semantic segmentation of building damage\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.dec2 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "\n",
    "        self.out = nn.Conv2d(32, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c1 = self.enc1(x)\n",
    "        c2 = self.enc2(self.pool(c1))\n",
    "\n",
    "        b = self.bottleneck(self.pool(c2))\n",
    "\n",
    "        u1 = self.up1(b)\n",
    "        d1 = self.dec1(torch.cat([u1, c2], dim=1))\n",
    "\n",
    "        u2 = self.up2(d1)\n",
    "        d2 = self.dec2(torch.cat([u2, c1], dim=1))\n",
    "\n",
    "        return self.out(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc65cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:59<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [01:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:53<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.2608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:50<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:50<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.2484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:54<00:00,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.2429\n",
      "‚úÖ Model saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss function, optimizer, and train the model for specified epochs\n",
    "model = UNet(NUM_CLASSES).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        masks = masks.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"unet_damage_model.pth\")\n",
    "print(\"‚úÖ Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c43ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved successfully at:\n",
      "c:\\Daily drive\\College\\sem 6\\Main Project DL\\unet_damage_model.pth\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = r\"c:\\Daily drive\\College\\sem 6\\Main Project DL\\unet_damage_model.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "print(\"‚úÖ Model saved successfully at:\")\n",
    "print(MODEL_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
